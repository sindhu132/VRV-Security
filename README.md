Log Analysis Script Description:

This Python script analyzes a raw log file generated by a web server. The log file records various details for each request, such as the IP address of the client, the requested endpoint, HTTP method, response status code, and other relevant information. The script processes this log file to generate insightful statistics, including:

Requests per IP Address: The total number of requests made by each unique IP address.
Most Accessed Endpoints: The endpoints that have been accessed the most.
Suspicious Activity Detection: Identification of suspicious activities based on failed login attempts, specifically looking for HTTP status code 401 and the presence of "Invalid credentials" in the additional info.
After processing the data, the script saves the results to a CSV file with the following sections:

Requests per IP: Lists each unique IP address along with the number of requests made by it.
Most Accessed Endpoint: Lists the endpoints sorted by the number of accesses.
Suspicious Activity: Identifies IP addresses with failed login attempts (status code 401) based on the presence of "Invalid credentials".
Features:
Regular Expression (Regex): The script uses a regular expression to extract specific details from each log line, such as IP address, timestamp, HTTP method, endpoint, status code, and any additional info.
Data Aggregation: It uses Python's defaultdict to count occurrences of IP addresses, endpoints, and failed login attempts.
CSV Output: The results are saved in a CSV file with a clear structure, allowing easy export and viewing in tools like Excel or Google Sheets.
Process Overview:
Log Parsing: The parse_log function reads the raw log file, applying the regex pattern to match log entries. It extracts relevant data for counting and identifying suspicious activity.
Data Aggregation: During parsing, the script updates dictionaries (ip_counts, endpoint_counts, failed_login_attempts) to store the count of requests per IP, requests per endpoint, and failed login attempts by IP.
CSV Writing: The save_to_csv function formats the results into a CSV file with three distinct sections: "Requests per IP", "Most Accessed Endpoint", and "Suspicious Activity".
Execution: The main function drives the script by calling the parsing and CSV writing functions, saving the analysis results in a user-specified output file.
CSV Output Example:
After running the script, the output CSV will be structured as follows:

Requests per IP:
IP Address	Request Count
192.168.1.1	10
203.0.113.5	5
10.0.0.2	8
...	...
Most Accessed Endpoint:
Endpoint	Access Count
/home	15
/login	12
/about	10
...	...
Suspicious Activity (Failed Login Attempts):
IP Address	Failed Login Count
192.168.1.1	3
203.0.113.5	2
...	...
How to Use:
Log File Path: Ensure that the log file path (log_file_path) is correctly set to the location of the raw log file you want to analyze.
Run the Script: Execute the script by running python script_name.py in the terminal or an IDE. Make sure the necessary permissions are granted for reading the log file and writing to the output CSV file.
Check the Results: The analysis will be saved in the log_analysis_results.csv file, which can then be opened using any CSV viewer (e.g., Excel, Google Sheets).
